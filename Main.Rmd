---
output:
  html_document: default
  pdf_document: default
---
# Basic Network Analysis of Wordbank Data

## Build Networks

List of libraries
```{r echo=TRUE, warning=FALSE, message=FALSE}
library(purrr) # fp library
library(readr) # read text data files (csv, etc.)
library(ggplot2) # plotting
library(langcog) # useful things used by Language and Cognition Lab
library(boot) # functions for bootstrapping
library(dplyr) # for working with datafram-like objects
library(tidyr) # for data tidying
library(wordbankr) # access to wordbank data
library(directlabels) # direct labeling of data in plots
library(stringr) # common string operations
library(lmtest) #  diagnostic checking in linear regression models
library(rwebppl) # interface to probabilistic programming language WebPPL
library(jsonlite) # JSON parser
library(nlme) # gaussian linear and nonlinear mixed-effects models
library(feather) # read and write fast lightweight binary columnar data
library(broom) # converts R function outputs to tidy data frames
library(HDInterval) # calculate highest density intervals of objects w/ pdf
library(BBmisc) # misc helper functions
library(igraph) # network analysis and visualization
library(knitr) # general-purpose tool for dynamic report generation
library(lemon) # functions for working w/ ggplot2 and knitr extensions
library(tibble) # modern dataframes
library(doParallel)
library(networkD3)
```


Import helper functions and configure RMarkdown
```{r echo=TRUE, warning=FALSE, message=FALSE}
source(paste(getwd(),"/helpers/all_helper.r",sep = ""), chdir = T)

knit_print.data.frame <- lemon_print # use kable when displaying tibbles in knit
```


Create vocab 
```{r echo=TRUE, warning=FALSE, message=FALSE}
# Import data from wordbank. Age of aquisition (in months, it starts with 16, 17,..) is that at which 50% of children can produce the word. The "defintion" is the word, the "unilemma"" is the translation in English.

# We also do naive triming at this point, this means we are ignoring homophone/polysemy (chiken (food), chiken (animals), etc,.. but we will have to be careful in our choices if we are preparing later for publication

vocab <- make_vocab_dataframe(lang="English (American)",
                              lang_form = "WS",
                              lex_class = "nouns") %>%
  trim_all_unilemma() %>%
  trim_all_definition() # %>%
  # distinct(uni_lemma, .keep_all = TRUE) # remove words with the same uni_lemma?
```

Build networks
```{r}
assoc_network <- function(vocab, max_age) {
  vocab_up_to_age = filter(vocab, age <= max_age)
  assoc_links <- make_assoc_pairs(lemma_list = vocab_up_to_age) %>%
    filter(link==1) %>%
    select(item, pair, item.definition, pair.definition)
  graph <- graph_from_data_frame(assoc_links, directed=FALSE, vertices=vocab_up_to_age) %>%
    simplify() %>%
    set.graph.attribute("name", "Assoc") %>%
    set.graph.attribute("age", max_age)
  return(graph)
}

feature_network <- function(vocab, max_age, shared_threshold) {
  vocab_up_to_age = filter(vocab, age <= max_age)
  feature_links <- make_feature_pairs(lemma_list = vocab_up_to_age) %>%
    filter(shared >= shared_threshold) %>%
    select(item, pair, item.definition, pair.definition)
  graph <- graph_from_data_frame(feature_links, directed=FALSE, vertices=vocab_up_to_age) %>%
    simplify() %>%
    set.graph.attribute("name", "Feature") %>%
    set.graph.attribute("age", max_age)
  return(graph)
}

ages <- vocab$age %>% unique() %>% sort()
assoc_networks <- list()
feature_networks <- list()
for (age in ages) {
  assoc_networks <- append(assoc_networks, list(assoc_network(vocab, age)))
  feature_networks <- append(feature_networks, list(feature_network(vocab, age, 1)))

}
```

## Network Analysis

### Large-Scale Structure of Networks

a la Steyvers 2005

```{r, results='asis'}
network_properties <- function(networks) {
  return( tibble(
  names = map_chr(networks, ~ .x$name),
  ages = map_dbl(networks, ~ .x$age) %>%
    as.integer(),
  vertices = map_int(networks, vcount),
  edges = map_dbl(networks, ecount) %>%
    as.integer(), # for some reason igraph ecount returns double
  avg_degree = map(networks, degree) %>%
    map_dbl(mean),
  avg_shortest_path = map_dbl(networks, mean_distance),
  diameter = map_dbl(networks, diameter) %>%
    as.integer(),
  clustering_coefficient = map_dbl(networks, transitivity),
  avg_shortest_path_random = 0, # either estimate or calculate values for random nets
  diameter_random = 0,
  clustering_coefficient_random = 0) )
}

network_properties(assoc_networks) # improve formatting
network_properties(feature_networks)
```

Visualize Networks
```{r}
plot_network <- function(g, remove_isolated=FALSE) {
  if (remove_isolated) {
    g <- delete.vertices(g, degree(g)==0)
  }
  
  plot(g, vertex.label=V(g)$uni_lemma, vertex.shape="none")
}

g <- assoc_networks[[6]]
plot_network(g, remove_isolated = FALSE)

plot(g,vertex.size=.01,vertex.label.cex=.8,
     layout=layout.fruchterman.reingold(g, niter=10000, 
                                        area=40*vcount(g)^2),
     edge.width=E(g)$weight)
```

Test Clique Percolation
```{r}
### Register Parallelisation (used by clique.community.opt.par())
cl <- makeCluster(4)
registerDoParallel(cl)
getDoParWorkers()


### Loading Benchmarks
#1 
g <- graph(c(1,2,1,3,1,4,2,3,3,4,4,5,4,6,5,6,5,8,5,7,6,8,6,7,7,8,7,9), directed=F)
#2
g <- make_graph("Zachary") #the karate network


#Execution of the different implementation of the algorithm
ptm <- proc.time()
res1<-clique.community(g,3)
proc.time() - ptm
ptm <- proc.time()
res2<-clique.community.opt(g,3)
proc.time() - ptm
ptm <- proc.time()
res3<-clique.community.opt.par(g,3)
proc.time() - ptm

identical(res1,res2)
identical(res2,res3)


### PLOT

#which one? the outcome is always the same
res <- res3

## Paint them to different colors
colbar <- rainbow( length(res)+1 )
for (i in seq(along=res)) {
  V(g)[ res[[i]] ]$color <- colbar[i+1]
}

## Paint the vertices in multiple communities to red
V(g)[ unlist(res)[ duplicated(unlist(res)) ] ]$color <- "red"

## Plot with the new colors
plot(g, layout=layout_with_fr, vertex.label=V(g)$name)


#REAL PERFORMANCE TEST
require(microbenchmark)
b1<-microbenchmark(t1<-clique.community(g,3),times = 100,unit = 'ms')
b2<-microbenchmark(t2<-clique.community.opt(g,3),times = 100,unit = 'ms')
b3<-microbenchmark(t2<-clique.community.opt.par(g,3),times = 100,unit = 'ms')
rbind(b1,b2,b3)
mean(b1$time)/mean(b2$time)
mean(b2$time)/mean(b3$time)
mean(b1$time)/mean(b3$time)
```

Initial Clique Analysis
```{r}
age <- 20
g <- assoc_networks[[age - 15]]
g <- delete.vertices(g, degree(g)==0)
res <- clique.community.opt(g,3)

## Paint them to different colors
colbar <- rainbow( length(res)+1 )
for (i in seq(along=res)) {
  V(g)[ res[[i]] ]$color <- colbar[i+1]
}

## Paint the vertices in multiple communities to red
V(g)[ unlist(res)[ duplicated(unlist(res)) ] ]$color <- "red"

## Plot with the new colors
plot(g, layout=layout_with_fr, vertex.label=V(g)$uni_lemma)
```

Dynamic Visualization
```{r}
karate <- make_graph("Zachary")
wc <- cluster_walktrap(karate)
members <- membership(wc)

# Convert to object suitable for networkD3
karate_d3 <- igraph_to_networkD3(karate, group = members)

# Create force directed network plot
forceNetwork(Links = karate_d3$links, Nodes = karate_d3$nodes,
             Source = 'source', Target = 'target', NodeID = 'name',
             Group = 'group')
```

